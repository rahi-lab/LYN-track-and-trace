{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bread.vis import *\n",
    "from bread.data import Features, SegmentationFile, Microscopy\n",
    "from bread.algo.lineage import LineageGuesser, LineageGuesserNN, LineageGuesserML, LineageGuesserNearestCell, accuracy\n",
    "from bread.data import Lineage\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions to extract features in batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required functions for feature extraction\n",
    "def extract_features(segmentation, guesser):\n",
    "    candidate_features = pd.DataFrame()\n",
    "    bud_ids, time_ids = segmentation.find_buds(\n",
    "    ).bud_ids, segmentation.find_buds().time_ids\n",
    "    f_list = []\n",
    "    for i, (bud_id, time_id) in enumerate(zip(bud_ids, time_ids)):\n",
    "        frame_range = guesser.segmentation.request_frame_range(\n",
    "            time_id, time_id + guesser.num_frames)\n",
    "        num_frames_available = guesser.num_frames\n",
    "        if len(frame_range) < 2:\n",
    "            # not enough frames\n",
    "            continue\n",
    "        if len(frame_range) < guesser.num_frames:\n",
    "            num_frames_available = len(frame_range)\n",
    "\n",
    "        # check the bud still exists !\n",
    "        for time_id_ in frame_range:\n",
    "            if bud_id not in guesser.segmentation.cell_ids(time_id_):\n",
    "                # bud has disappeared\n",
    "                continue\n",
    "        selected_times = [i for i in range(\n",
    "            time_id, time_id + num_frames_available)]\n",
    "        try:\n",
    "            candidate_parents = guesser._candidate_parents(\n",
    "                time_id, nearest_neighbours_of=bud_id)\n",
    "            for c_id, candidate in enumerate(candidate_parents):\n",
    "                features, f_list = guesser._get_features(\n",
    "                    bud_id, candidate, time_id, selected_times)\n",
    "                new_row = {'bud_id': bud_id,\n",
    "                           'candid_id': candidate, 'time_id': time_id}\n",
    "                new_row.update(features)\n",
    "                new_df = pd.DataFrame(new_row, index=[0])\n",
    "                candidate_features = pd.concat([candidate_features, new_df])\n",
    "        except Exception as e:\n",
    "            print(\"Error for bud {} at time {} with candidate: {}\".format(\n",
    "                bud_id, time_id, e))\n",
    "    return candidate_features, f_list\n",
    "\n",
    "# turn features in to a matrix format\n",
    "\n",
    "\n",
    "def get_custom_matrix_features(features_all, lineage_gt, feature_list, filling_features=[-100 for i in range(100)]):\n",
    "    # Generate np array of feature sets for each bud\n",
    "    lineage = lineage_gt.copy()\n",
    "    # remove the rows with parent_GT = -1 (no parent) and the rows with candid_GT = -2 (disappearing buds)\n",
    "    lineage = lineage.loc[lineage.parent_GT != -1]\n",
    "    lineage = lineage.loc[lineage.parent_GT != -2]\n",
    "    lineage = lineage.loc[lineage.parent_GT != -3]\n",
    "    candidate_features = features_all.copy()\n",
    "    features_list = []\n",
    "    filling_features = filling_features[:len(feature_list)]\n",
    "    parent_index_list = []\n",
    "    candidate_list = []\n",
    "    for bud, colony in lineage[['bud_id', 'colony']].values:\n",
    "        bud_data = candidate_features.loc[(candidate_features['bud_id'] == bud) & (\n",
    "            candidate_features['colony'] == colony)]\n",
    "        candidates = bud_data['candid_id'].to_numpy()\n",
    "        features = bud_data[feature_list].to_numpy()\n",
    "        if (len(candidates) == 0):\n",
    "            if (len(bud_data) == 0):\n",
    "                # bud only appears in the last frame\n",
    "                lineage.drop(lineage.loc[(lineage['bud_id'] == bud) & (lineage.colony == colony)].index,\n",
    "                             inplace=True)\n",
    "            else:\n",
    "                print('no candidates', bud, colony, candidates)\n",
    "            continue\n",
    "        elif candidates.shape[0] < 4:\n",
    "            n_rows = 4 - candidates.shape[0]\n",
    "            if candidates.shape[0] == 1:\n",
    "                # only one candidate\n",
    "                # fill with -100\n",
    "                candidates = np.concatenate(\n",
    "                    (candidates, np.array([-3 for i in range(n_rows)])), axis=0)\n",
    "                features = np.concatenate(\n",
    "                    (features, np.full((n_rows, features.shape[1]), -100)), axis=0)\n",
    "            else:  # more than one candidate\n",
    "                parent = int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
    "                    lineage['colony'] == colony), 'parent_GT'].iloc[0])\n",
    "                not_parent_data = candidate_features.loc[(candidate_features['bud_id'] == bud) & (\n",
    "                    candidate_features['colony'] == colony) & (candidate_features['candid_id'] != parent)]\n",
    "                filling_features = not_parent_data[feature_list].to_numpy()[0]\n",
    "                features = np.concatenate(\n",
    "                    (features, [filling_features for i in range(n_rows)]), axis=0)\n",
    "                candidates = np.concatenate(\n",
    "                    (candidates, [-3 for i in range(n_rows)]), axis=0)\n",
    "        elif features.shape[0] > 4:\n",
    "            sorted_indices = np.argsort(features[:, 0])\n",
    "            print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
    "                lineage['colony'] == colony), 'parent_GT']))\n",
    "            # slice the top 4 rows\n",
    "            features = features[sorted_indices[:4]]\n",
    "            candidates = candidates[sorted_indices[:4]]\n",
    "\n",
    "        parent = int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
    "            lineage['colony'] == colony), 'parent_GT'].iloc[0])\n",
    "        if (parent not in candidates):\n",
    "            print('parent not in candidates', bud, colony, candidates, parent)\n",
    "            lineage.drop(lineage.loc[(lineage['bud_id'] == bud) & (\n",
    "                lineage.colony == colony)].index, inplace=True)\n",
    "            continue\n",
    "        else:\n",
    "            parent_index = np.where(candidates == parent)[0][0]\n",
    "        parent_index_list.append(parent_index)\n",
    "        features_list.append(features)\n",
    "        candidate_list.append(candidates)\n",
    "    lineage['features'] = features_list\n",
    "    lineage['candidates'] = candidate_list\n",
    "    lineage['parent_index_in_candidates'] = parent_index_list\n",
    "    return lineage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions for training neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "\n",
    "class BudDataset(Dataset):\n",
    "    def __init__(self, data, augment=True):\n",
    "        X = data['features'].to_numpy()\n",
    "        labels = data['parent_index_in_candidates'].to_numpy()\n",
    "        if (augment):\n",
    "            X, labels = generate_all_permutations(X, labels)\n",
    "        X = flatten_3d_array(X)\n",
    "        self.data = torch.tensor(X, dtype=torch.float32)\n",
    "        self.labels = torch.zeros(len(labels), 4)  # initialize labels as zeros\n",
    "        for i, label in enumerate(labels):\n",
    "            if label != -1:\n",
    "                # set the position of the correct parent to 1\n",
    "                self.labels[i][label] = 1.0\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# lineage NN with mask\n",
    "\n",
    "\n",
    "class LineageNN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(LineageNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()  # create an empty nn.ModuleList\n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(nn.Linear(layers[i], layers[i+1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mask = (x != -100).float()\n",
    "        x = x * mask  # apply the mask to zero out invalid values\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = F.relu(layer(x))\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# functions to deal with data\n",
    "\n",
    "\n",
    "def flatten_3d_array(arr):\n",
    "    \"\"\"\n",
    "    Flattens a 3-dimensional numpy array while keeping the first dimension unchanged\n",
    "    \"\"\"\n",
    "    if arr.ndim == 1:\n",
    "        arr2 = np.array([arr[i] for i in range(len(arr))])\n",
    "        arr = np.stack(arr2)\n",
    "    shape = arr.shape\n",
    "    new_shape = (shape[0], np.prod(shape[1:]))\n",
    "    return arr.reshape(new_shape)\n",
    "\n",
    "\n",
    "def permute_matrix(matrix, row_id):\n",
    "    \"\"\"\n",
    "    Generates all possible permutations of a matrix  rows\n",
    "    it takes row_index as input, which is a one-hot encoded label for the classification \n",
    "    and outputs the one-hot encoded labels of the permutated matrices\n",
    "    \"\"\"\n",
    "    # Get the number of rows in the matrix\n",
    "    rows = len(matrix)\n",
    "\n",
    "    # Get all possible permutations of the row indices\n",
    "    permutations = list(itertools.permutations(range(rows)))\n",
    "\n",
    "    # Use list comprehension to create a list of all permuted matrices\n",
    "    permuted_matrices = [np.array([matrix[i] for i in permutation])\n",
    "                         for permutation in permutations]\n",
    "\n",
    "    # Use list comprehension to find the index of the specified row in each permuted matrix\n",
    "    row_indices = [list(permutation).index(row_id)\n",
    "                   for permutation in permutations]\n",
    "\n",
    "    return permuted_matrices, row_indices\n",
    "\n",
    "\n",
    "def generate_all_permutations(data, labels):\n",
    "    \"\"\"\n",
    "    Generates all posible permutations for matrices in data \n",
    "    and the corresponding labels\n",
    "    Labels should be integers\n",
    "    \"\"\"\n",
    "\n",
    "    permuted_matrices_list = []\n",
    "    permuted_labels_list = []\n",
    "\n",
    "    for matrix, label in zip(data, labels):\n",
    "        permuted_matrices, permuted_labels = permute_matrix(matrix, label)\n",
    "        permuted_matrices_list.extend(permuted_matrices)\n",
    "        permuted_labels_list.extend(permuted_labels)\n",
    "\n",
    "    return np.array(permuted_matrices_list), np.array(permuted_labels_list)\n",
    "\n",
    "# functions to train and test the model\n",
    "\n",
    "\n",
    "def train_nn(train_df, eval_df, save_path='bst_nn.pth', config={}, seed=42):\n",
    "    # Initialize wandb\n",
    "    use_wandb = config['use_wandb']\n",
    "    if (use_wandb):\n",
    "        wandb.init(project=\"lineage_tracing\", group='with_mask', config=config)\n",
    "\n",
    "    # initialize neural network\n",
    "    # manualy set the seed to enable reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    net = LineageNN(layers=config['layers'])\n",
    "\n",
    "    # define your loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=config['lr'])\n",
    "    scheduler = lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1, end_factor=0.01, total_iters=200)\n",
    "\n",
    "    train_bud_dataset = BudDataset(train_df, augment=config['augment'])\n",
    "    train_bud_dataloader = DataLoader(\n",
    "        train_bud_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    eval_bud_dataset = BudDataset(eval_df, augment=False)\n",
    "    eval_bud_dataloader = DataLoader(\n",
    "        eval_bud_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "    # train your neural network\n",
    "    patient = 0\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(config['epoch_n']):\n",
    "        running_loss = 0.0\n",
    "        # training loop\n",
    "        predicted_all = []\n",
    "        labels_all = []\n",
    "        net.train()\n",
    "        for i, data in enumerate(train_bud_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass\n",
    "            outputs = net(inputs)\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted_all.extend(predicted)\n",
    "            labels_all.extend(labels)\n",
    "            # backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            scheduler.step()\n",
    "        train_accuracy = accuracy_score(labels_all, predicted_all)\n",
    "        # eval loop\n",
    "        predicted_all = []\n",
    "        labels_all = []\n",
    "        net.eval()\n",
    "        for i, data in enumerate(eval_bud_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            with torch.no_grad():\n",
    "                outputs = net(inputs)\n",
    "            _, labels = torch.max(labels.data, 1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted_all.extend(predicted)\n",
    "            labels_all.extend(labels)\n",
    "        eval_accuracy = accuracy_score(labels_all, predicted_all)\n",
    "        if (eval_accuracy > best_accuracy):\n",
    "            best_accuracy = eval_accuracy\n",
    "            best_model = net\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "            patient = 0\n",
    "        else:\n",
    "            patient += 1\n",
    "        if (patient > config['patience']):\n",
    "            print('early stopping at ', epoch, 'LR: ',\n",
    "                  optimizer.param_groups[0]['lr'])\n",
    "            break\n",
    "        if (use_wandb):\n",
    "            wandb_log = {'epoch': epoch, 'patience': patient, 'eval_accuracy': eval_accuracy,\n",
    "                         'train_accuracy': train_accuracy, 'best_accuracy': best_accuracy, 'lr': optimizer.param_groups[0]['lr']}\n",
    "            wandb.log(wandb_log)\n",
    "    return best_model, best_accuracy\n",
    "\n",
    "\n",
    "def test_nn(model, test_df):\n",
    "    bud_dataset = BudDataset(test_df, augment=False)\n",
    "    bud_dataloader = DataLoader(\n",
    "        bud_dataset, batch_size=len(test_df), shuffle=False)\n",
    "    for i, data in enumerate(bud_dataloader, 0):\n",
    "        if (i > 0):\n",
    "            print('more than one batch')\n",
    "        inputs, labels = data\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        _, labels = torch.max(labels.data, 1)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = accuracy_score(predicted, labels)\n",
    "    print('test accuracy', accuracy)\n",
    "    test_df['predicted'] = predicted\n",
    "    return test_df, accuracy\n",
    "\n",
    "\n",
    "def cv_nn(df, config={}, seed=42):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    X = df['features'].to_numpy()\n",
    "    y = df['parent_index_in_candidates'].to_numpy()\n",
    "    # repeat df because it necessary for the function to have two arguments\n",
    "    skf.get_n_splits(X, y)\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    i = 0\n",
    "    # repeat df because it necessary for the function to have two arguments\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        i = i+1\n",
    "        config['cv_number'] = i\n",
    "        print('config: ', config)\n",
    "        train_df = df.iloc[train_index]\n",
    "        test_df = df.iloc[test_index]\n",
    "        net, accuracy = train_nn(train_df, test_df, config=config, seed=seed)\n",
    "        accuracies.append(accuracy)\n",
    "        models.append(net)\n",
    "\n",
    "    print('accuracy: ', np.mean(accuracies), '+/-', np.std(accuracies))\n",
    "    return models, accuracies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A pipeline to train a neural network based on given arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values and arguments\n",
    "selected_keys = ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first',\n",
    "                 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud']\n",
    "args = {'fov': 0, 'bud_distance_max': 12, 'num_frames': 8,\n",
    "        'num_frames_refractory': 0, 'normalized': True, 'selected_keys': selected_keys}\n",
    "# config for trianing neural network\n",
    "config = {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [\n",
    "    64, 64, 4], 'augment': True, 'features': selected_keys, 'dist_threshold': args['bud_distance_max'], 'num_frames': args['num_frames'], 'normalized': args['normalized'], 'use_wandb': False}\n",
    "data_path = '../../../data_edited/'\n",
    "\n",
    "res = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth data\n",
    "lin_gt_all = pd.DataFrame()\n",
    "for colony in range(0, 6):\n",
    "    lineage_gt_path = os.path.join(\n",
    "        data_path, f'colony00{colony}_lineage_gt.csv')\n",
    "    lin_truth = pd.read_csv(lineage_gt_path)\n",
    "    lin_truth['colony'] = colony\n",
    "    lin_gt_all = pd.concat([lin_gt_all, lin_truth])\n",
    "lin_gt_all.rename(columns={'# parent_id': 'parent_GT'}, inplace=True)\n",
    "lin_gt_all.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing colony 0\n",
      "No model was provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #1 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n",
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #2 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 1 at time 0 with candidate: No candidate parents have been found for in frame #0.\n",
      "Error for bud 2 at time 0 with candidate: No candidate parents have been found for in frame #0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #3 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n",
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #4 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 3 at time 0 with candidate: No candidate parents have been found for in frame #0.\n",
      "Error for bud 4 at time 0 with candidate: No candidate parents have been found for in frame #0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/data/_data.py:603: MultipleContoursWarning: OpenCV returned multiple contours, 2 found.\n",
      "  warnings.warn(Contour.MultipleContoursWarning(len(contours_cv)))\n",
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #44 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 44 at time 74 with candidate: No candidate parents have been found for in frame #74.\n",
      "Error for bud 305 at time 140 with candidate: Unable to find cell_id=94 at time_id=147 in the segmentation.\n",
      "Error for bud 306 at time 140 with candidate: Unable to find cell_id=36 at time_id=147 in the segmentation.\n",
      "Error for bud 307 at time 140 with candidate: Unable to find cell_id=74 at time_id=147 in the segmentation.\n",
      "Error for bud 308 at time 140 with candidate: Unable to find cell_id=160 at time_id=147 in the segmentation.\n",
      "Error for bud 309 at time 140 with candidate: Unable to find cell_id=42 at time_id=147 in the segmentation.\n",
      "Error for bud 310 at time 140 with candidate: Unable to find cell_id=22 at time_id=147 in the segmentation.\n",
      "Error for bud 311 at time 140 with candidate: Unable to find cell_id=109 at time_id=147 in the segmentation.\n",
      "Error for bud 312 at time 140 with candidate: Unable to find cell_id=1 at time_id=147 in the segmentation.\n",
      "Error for bud 313 at time 140 with candidate: Unable to find cell_id=10 at time_id=147 in the segmentation.\n",
      "Error for bud 314 at time 140 with candidate: Unable to find cell_id=31 at time_id=147 in the segmentation.\n",
      "Error for bud 315 at time 140 with candidate: Unable to find cell_id=17 at time_id=147 in the segmentation.\n",
      "Error for bud 316 at time 140 with candidate: Unable to find cell_id=59 at time_id=147 in the segmentation.\n",
      "Error for bud 317 at time 140 with candidate: Unable to find cell_id=67 at time_id=147 in the segmentation.\n",
      "Error for bud 318 at time 140 with candidate: Unable to find cell_id=8 at time_id=147 in the segmentation.\n",
      "Error for bud 319 at time 141 with candidate: Unable to find cell_id=6 at time_id=147 in the segmentation.\n",
      "Error for bud 320 at time 141 with candidate: Unable to find cell_id=71 at time_id=147 in the segmentation.\n",
      "Error for bud 321 at time 141 with candidate: Unable to find cell_id=12 at time_id=147 in the segmentation.\n",
      "Error for bud 322 at time 141 with candidate: Unable to find cell_id=118 at time_id=147 in the segmentation.\n",
      "Error for bud 323 at time 141 with candidate: Unable to find cell_id=76 at time_id=147 in the segmentation.\n",
      "Error for bud 324 at time 142 with candidate: Unable to find cell_id=21 at time_id=147 in the segmentation.\n",
      "Error for bud 325 at time 142 with candidate: Unable to find cell_id=129 at time_id=147 in the segmentation.\n",
      "Error for bud 326 at time 142 with candidate: Unable to find cell_id=53 at time_id=147 in the segmentation.\n",
      "Error for bud 327 at time 142 with candidate: Unable to find cell_id=54 at time_id=147 in the segmentation.\n",
      "Error for bud 328 at time 142 with candidate: Unable to find cell_id=57 at time_id=147 in the segmentation.\n",
      "Error for bud 329 at time 142 with candidate: Unable to find cell_id=35 at time_id=147 in the segmentation.\n",
      "Error for bud 330 at time 142 with candidate: Unable to find cell_id=47 at time_id=147 in the segmentation.\n",
      "Error for bud 331 at time 142 with candidate: Unable to find cell_id=88 at time_id=147 in the segmentation.\n",
      "Error for bud 332 at time 142 with candidate: Unable to find cell_id=104 at time_id=147 in the segmentation.\n",
      "Error for bud 333 at time 142 with candidate: No candidate parents have been found for in frame #142.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #333 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 334 at time 142 with candidate: Unable to find cell_id=5 at time_id=147 in the segmentation.\n",
      "Error for bud 335 at time 142 with candidate: Unable to find cell_id=161 at time_id=147 in the segmentation.\n",
      "Error for bud 336 at time 143 with candidate: Unable to find cell_id=106 at time_id=147 in the segmentation.\n",
      "Error for bud 337 at time 143 with candidate: Unable to find cell_id=333 at time_id=147 in the segmentation.\n",
      "Error for bud 338 at time 143 with candidate: Unable to find cell_id=25 at time_id=147 in the segmentation.\n",
      "Error for bud 339 at time 143 with candidate: Unable to find cell_id=160 at time_id=147 in the segmentation.\n",
      "Error for bud 340 at time 143 with candidate: Unable to find cell_id=19 at time_id=147 in the segmentation.\n",
      "Error for bud 341 at time 143 with candidate: No candidate parents have been found for in frame #143.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #341 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 342 at time 143 with candidate: Unable to find cell_id=22 at time_id=147 in the segmentation.\n",
      "Error for bud 343 at time 143 with candidate: Unable to find cell_id=48 at time_id=147 in the segmentation.\n",
      "Error for bud 344 at time 143 with candidate: Unable to find cell_id=31 at time_id=147 in the segmentation.\n",
      "Error for bud 345 at time 143 with candidate: Unable to find cell_id=17 at time_id=147 in the segmentation.\n",
      "Error for bud 346 at time 143 with candidate: Unable to find cell_id=79 at time_id=147 in the segmentation.\n",
      "Error for bud 347 at time 144 with candidate: Unable to find cell_id=54 at time_id=147 in the segmentation.\n",
      "Error for bud 348 at time 144 with candidate: Unable to find cell_id=95 at time_id=147 in the segmentation.\n",
      "Error for bud 349 at time 144 with candidate: Unable to find cell_id=52 at time_id=147 in the segmentation.\n",
      "Error for bud 350 at time 144 with candidate: Unable to find cell_id=89 at time_id=147 in the segmentation.\n",
      "Error for bud 351 at time 144 with candidate: Unable to find cell_id=110 at time_id=147 in the segmentation.\n",
      "Error for bud 352 at time 144 with candidate: Unable to find cell_id=20 at time_id=147 in the segmentation.\n",
      "Error for bud 353 at time 144 with candidate: Unable to find cell_id=117 at time_id=147 in the segmentation.\n",
      "Error for bud 354 at time 144 with candidate: Unable to find cell_id=21 at time_id=147 in the segmentation.\n",
      "Error for bud 355 at time 144 with candidate: Unable to find cell_id=11 at time_id=147 in the segmentation.\n",
      "Error for bud 356 at time 145 with candidate: Unable to find cell_id=55 at time_id=147 in the segmentation.\n",
      "Error for bud 357 at time 145 with candidate: Unable to find cell_id=73 at time_id=147 in the segmentation.\n",
      "Error for bud 358 at time 145 with candidate: Unable to find cell_id=185 at time_id=147 in the segmentation.\n",
      "Error for bud 359 at time 145 with candidate: Unable to find cell_id=90 at time_id=147 in the segmentation.\n",
      "Error for bud 360 at time 145 with candidate: Unable to find cell_id=144 at time_id=147 in the segmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/data/_data.py:603: MultipleContoursWarning: OpenCV returned multiple contours, 4 found.\n",
      "  warnings.warn(Contour.MultipleContoursWarning(len(contours_cv)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 361 at time 146 with candidate: Unable to find cell_id=341 at time_id=147 in the segmentation.\n",
      "Error for bud 362 at time 146 with candidate: Unable to find cell_id=43 at time_id=147 in the segmentation.\n",
      "Error for bud 363 at time 146 with candidate: Unable to find cell_id=86 at time_id=147 in the segmentation.\n",
      "Error for bud 364 at time 146 with candidate: Unable to find cell_id=88 at time_id=147 in the segmentation.\n",
      "Error for bud 365 at time 146 with candidate: Unable to find cell_id=208 at time_id=147 in the segmentation.\n",
      "Error for bud 366 at time 146 with candidate: Unable to find cell_id=26 at time_id=147 in the segmentation.\n",
      "Error for bud 367 at time 146 with candidate: Unable to find cell_id=91 at time_id=147 in the segmentation.\n",
      "Error for bud 368 at time 146 with candidate: Unable to find cell_id=34 at time_id=147 in the segmentation.\n",
      "Error for bud 369 at time 146 with candidate: Unable to find cell_id=23 at time_id=147 in the segmentation.\n",
      "Error for bud 370 at time 146 with candidate: Unable to find cell_id=5 at time_id=147 in the segmentation.\n",
      "Error for bud 371 at time 146 with candidate: Unable to find cell_id=174 at time_id=147 in the segmentation.\n",
      "Processing colony 1\n",
      "No model was provided\n",
      "Processing colony 2\n",
      "No model was provided\n",
      "Processing colony 3\n",
      "No model was provided\n",
      "Error for bud 73 at time 163 with candidate: Unable to find cell_id=53 at time_id=167 in the segmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #77 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 77 at time 167 with candidate: No candidate parents have been found for in frame #167.\n",
      "Processing colony 4\n",
      "No model was provided\n",
      "Error for bud 40 at time 123 with candidate: Unable to find cell_id=40 at time_id=124 in the segmentation.\n",
      "Error for bud 50 at time 136 with candidate: Unable to find cell_id=34 at time_id=141 in the segmentation.\n",
      "Error for bud 55 at time 137 with candidate: Unable to find cell_id=34 at time_id=141 in the segmentation.\n",
      "Error for bud 82 at time 154 with candidate: Unable to find cell_id=82 at time_id=161 in the segmentation.\n",
      "Error for bud 87 at time 157 with candidate: Unable to find cell_id=60 at time_id=161 in the segmentation.\n",
      "Error for bud 105 at time 169 with candidate: Unable to find cell_id=67 at time_id=170 in the segmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farzaneh/Documents/Bread/bread/src/bread/algo/lineage/_lineage.py:219: BreadWarning: cell #114 does not have nearest neighbours with a distance less than 12, and flexible_threshold is False.\n",
      "  warnings.warn(BreadWarning(f'cell #{nearest_neighbours_of} does not have nearest neighbours with a distance less than {self.nn_threshold}, and flexible_threshold is {self.flexible_nn_threshold}.'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for bud 114 at time 173 with candidate: No candidate parents have been found for in frame #173.\n",
      "Processing colony 5\n",
      "No model was provided\n"
     ]
    }
   ],
   "source": [
    "# extracting features and normalizing them if required\n",
    "features_all = pd.DataFrame()\n",
    "for colony in range(0, 6):\n",
    "    print(f'Processing colony {colony}')\n",
    "    segmentation_file = os.path.join(\n",
    "        data_path, f'colony00{colony}_segmentation.h5')\n",
    "    segmentation = SegmentationFile.from_h5(\n",
    "        segmentation_file).get_segmentation('FOV'+str(args['fov']))\n",
    "    guesser = LineageGuesserNN(\n",
    "        segmentation=segmentation,\n",
    "        nn_threshold=args['bud_distance_max'],\n",
    "        num_frames_refractory=args['num_frames_refractory'],\n",
    "        num_frames=args['num_frames'],\n",
    "    )\n",
    "    features, f_list = extract_features(segmentation, guesser)\n",
    "    features['colony'] = colony\n",
    "    features_all = pd.concat([features_all, features])\n",
    "X = features_all[selected_keys]\n",
    "scaler = MinMaxScaler()\n",
    "# save this scaler to use it later for normalization\n",
    "X_norm = scaler.fit_transform(X)\n",
    "if (args['normalized']):\n",
    "    # normalize features\n",
    "    features_all_normalized = features_all.copy()\n",
    "    features_all_normalized[selected_keys] = X_norm\n",
    "    features_all = features_all_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 4 candidates 141 0 [  3  54  68  93 134] [1 0 4 3 2] 54\n",
      "more than 4 candidates 146 0 [ 14  19  49 131 144] [2 0 1 4 3] 14\n",
      "more than 4 candidates 152 0 [  9  23  48  91 111] [1 4 0 2 3] 23\n",
      "more than 4 candidates 166 0 [  3  54  68  93 134] [4 3 0 1 2] 54\n",
      "more than 4 candidates 168 0 [  1  33  77 154 160] [1 2 4 3 0] 1\n",
      "parent not in candidates 168 0 [ 33  77 160 154] 1\n",
      "more than 4 candidates 221 0 [  9  19  77 160 168] [2 3 1 4 0] 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 4 candidates 264 0 [ 94 105 167 191 236] [2 0 1 4 3] 94\n",
      "more than 4 candidates 266 0 [ 48  80 137 183 242] [2 1 4 3 0] 137\n",
      "more than 4 candidates 276 0 [ 23  48 152 182 265] [4 1 3 0 2] 265\n",
      "more than 4 candidates 283 0 [ 11  27 105 192 237] [2 3 1 4 0] 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 4 candidates 52 1 [ 3  7 13 25 29] [3 4 0 2 1] 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n",
      "/tmp/ipykernel_868478/3943266088.py:80: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  print('more than 4 candidates', bud, colony, candidates, sorted_indices, int(lineage.loc[(lineage['bud_id'] == bud) & (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 4 candidates 69 3 [12 19 21 42 67] [4 0 1 2 3] 12\n",
      "more than 4 candidates 87 3 [18 37 39 59 71] [1 2 0 4 3] 37\n",
      "more than 4 candidates 92 3 [22 31 49 50 75] [3 4 0 1 2] 22\n",
      "parent not in candidates 68 4 [ 4  8 64 -3] 39\n"
     ]
    }
   ],
   "source": [
    "# get matrix features\n",
    "matrix_features = get_custom_matrix_features(\n",
    "    features_all, lin_gt_all, selected_keys)\n",
    "matrix_features.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "# split to train and test (5-fold cross validation take care of the rest)\n",
    "test_df = matrix_features.sample(frac=0.2, random_state=4)\n",
    "train_df = matrix_features.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:  {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [64, 64, 4], 'augment': True, 'features': ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first', 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud'], 'dist_threshold': 12, 'num_frames': 8, 'normalized': True, 'use_wandb': False, 'cv_number': 1}\n",
      "early stopping at  14 LR:  9.99999999999999e-05\n",
      "config:  {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [64, 64, 4], 'augment': True, 'features': ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first', 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud'], 'dist_threshold': 12, 'num_frames': 8, 'normalized': True, 'use_wandb': False, 'cv_number': 2}\n",
      "early stopping at  14 LR:  9.99999999999999e-05\n",
      "config:  {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [64, 64, 4], 'augment': True, 'features': ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first', 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud'], 'dist_threshold': 12, 'num_frames': 8, 'normalized': True, 'use_wandb': False, 'cv_number': 3}\n",
      "early stopping at  13 LR:  9.99999999999999e-05\n",
      "config:  {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [64, 64, 4], 'augment': True, 'features': ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first', 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud'], 'dist_threshold': 12, 'num_frames': 8, 'normalized': True, 'use_wandb': False, 'cv_number': 4}\n",
      "early stopping at  14 LR:  9.99999999999999e-05\n",
      "config:  {'owner': 'train_pipeline', 'epoch_n': 200, 'patience': 10, 'lr': 0.01, 'batch_size': 256, 'layers': [64, 64, 4], 'augment': True, 'features': ['dist_0', 'dist_std', 'poly_fit_budcm_budpt', 'poly_fit_expansion_vector', 'position_bud_std', 'position_bud_max', 'position_bud_min', 'position_bud_last', 'position_bud_first', 'orientation_bud_std', 'orientation_bud_max', 'orientation_bud_min', 'orientation_bud_last', 'orientation_bud_first', 'orientation_bud_last_minus_first', 'plyfit_orientation_bud'], 'dist_threshold': 12, 'num_frames': 8, 'normalized': True, 'use_wandb': False, 'cv_number': 5}\n",
      "early stopping at  13 LR:  9.99999999999999e-05\n",
      "accuracy:  0.8811008929761428 +/- 0.01829194368117267\n",
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.9150326797385621\n",
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.9019607843137255\n"
     ]
    }
   ],
   "source": [
    "# train the model using 5-fold cross validation with fixed seed\n",
    "models, accuracies = cv_nn(train_df, config=config, seed=42)\n",
    "res['val_accuracy'] = np.mean(accuracies)\n",
    "res['val_accuracy_std'] = np.std(accuracies)\n",
    "# test all of the models fom 5-fold cv on the test set\n",
    "accuracies_test = []\n",
    "for model in models:\n",
    "    pred, accuracy = test_nn(model, test_df)\n",
    "    accuracies_test.append(accuracy)\n",
    "res['internal_test_accuracy'] = np.mean(accuracies_test)\n",
    "res['internal_test_accuracy_std'] = np.std(accuracies_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_accuracy': 0.8811008929761428,\n",
       " 'val_accuracy_std': 0.01829194368117267,\n",
       " 'internal_test_accuracy': 0.9006535947712418,\n",
       " 'internal_test_accuracy_std': 0.007622159339667032}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.8794788273615635\n",
      "test accuracy 0.9150326797385621\n",
      "test accuracy 0.8859934853420195\n",
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.8827361563517915\n",
      "test accuracy 0.8954248366013072\n",
      "test accuracy 0.8843648208469055\n",
      "test accuracy 0.9019607843137255\n",
      "test accuracy 0.8827361563517915\n",
      "best model saved : best_model_fake_candid_thresh12_frame_num8_normalized_True.pth\n"
     ]
    }
   ],
   "source": [
    "# save the best model\n",
    "best_model = 0\n",
    "best_sum_accuracy = 0\n",
    "for model in models:\n",
    "    _, test_accuracy = test_nn(model, test_df)\n",
    "    _, train_accuracy = test_nn(model, train_df)\n",
    "    if (train_accuracy+test_accuracy > best_sum_accuracy):\n",
    "        best_model = model\n",
    "        best_sum_accuracy = train_accuracy+test_accuracy\n",
    "torch.save(best_model.state_dict(), 'best_model_with_fake_candid_thresh{}_frame_num{}_normalized_{}.pth'.format(\n",
    "    args['bud_distance_max'], args['num_frames'], args['normalized']))\n",
    "print('best model saved :',  'best_model_fake_candid_thresh{}_frame_num{}_normalized_{}.pth'.format(\n",
    "    args['bud_distance_max'], args['num_frames'], args['normalized']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.9150326797385621\n"
     ]
    }
   ],
   "source": [
    "# test the best model on the test set\n",
    "_, test_accuracy = test_nn(best_model, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lineage_tracing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
